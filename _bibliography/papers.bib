---
---
@string{aps = {American Physical Society,}}

@inproceedings{olfmlm,
    title = "{O}n {L}osses for {M}odern {L}anguage {M}odels",
    author = "Aroca-Ouellette, St{\'e}phane  and
      Rudzicz, Frank",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
    month = nov,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-main.403",
    doi = "10.18653/v1/2020.emnlp-main.403",
    pages = "4970--4981",
    abstract = "BERT set many state-of-the-art results over varied NLU benchmarks by pre-training over two tasks: masked language modelling (MLM) and next sentence prediction (NSP), the latter of which has been highly criticized. In this paper, we 1) clarify NSP{'}s effect on BERT pre-training, 2) explore fourteen possible auxiliary pre-training tasks, of which seven are novel to modern language models, and 3) investigate different ways to include multiple tasks into pre-training. We show that NSP is detrimental to training due to its context splitting and shallow semantic signal. We also identify six auxiliary pre-training tasks {--} sentence ordering, adjacent sentence prediction, TF prediction, TF-IDF prediction, a FastSent variant, and a Quick Thoughts variant {--} that outperform a pure MLM baseline. Finally, we demonstrate that using multiple tasks in a multi-task pre-training framework provides better results than using any single auxiliary task. Using these methods, we outperform BERTBase on the GLUE benchmark using fewer than a quarter of the training tokens.",
    selected=true
}

@article{cav,
  doi = {10.1371/journal.pone.0211659},
  url = {https://doi.org/10.1371%2Fjournal.pone.0211659},
  year = 2019,
  month = {aug},
  publisher = {Public Library of Science ({PLoS})},
  volume = {14},
  number = {8},
  pages = {e0211659},
  author = {Ismail M. Khater and Stephane T. Aroca-Ouellette and Fanrui Meng and Ivan Robert Nabi and Ghassan Hamarneh},
  editor = {David Mayerich},
  title = {Caveolae and scaffold detection from single molecule localization microscopy data using deep learning},
  journal = {{PLOS} {ONE}}
} 

@inproceedings{aroca-ouellette-etal-2021-prost,
    title = "{PROST}: {P}hysical Reasoning about Objects through Space and Time",
    author = "Aroca-Ouellette, St{\'e}phane  and
      Paik, Cory  and
      Roncone, Alessandro  and
      Kann, Katharina",
    booktitle = "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-acl.404",
    doi = "10.18653/v1/2021.findings-acl.404",
    pages = "4597--4608",
    abstract = "We present a new probing dataset named \emph{PROST: Physical Reasoning about Objects Through Space and Time}. 
This dataset contains 18,736 multiple-choice questions made from 14 manually curated templates, covering 10 physical reasoning concepts. All questions are designed to probe both causal and masked language models in a zero-shot setting. We conduct an extensive analysis which demonstrates that state-of-the-art pretrained models are inadequate at physical reasoning: they are influenced by the order in which answer options are presented to them, they struggle when the superlative in a question is inverted (e.g., \textit{most} $\leftrightarrow$ \textit{least}), and increasing the amount of pretraining data and parameters only yields minimal improvements. These results provide support for the hypothesis that current pretrained models' ability to reason about physical interactions is inherently limited by a lack of real world experience. By highlighting these limitations, we hope to motivate the development of models with a human-like understanding of the physical world."
    selected=true
}